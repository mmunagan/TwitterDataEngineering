{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: For ALL bashscripts in this project, I copied and pasted bash scripts into code cells because JD told me to do it as pasting it into markdown cells deleted some part of the script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Finding Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 a-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ff', 3522), ('nowplaying', 1799), ('fb', 1362), ('mm', 1017), ('fail', 628), ('random', 601), ('haiti', 586), ('shoutout', 516), ('musicmonday', 451), ('followfriday', 449)]\n",
      "Time: 7.478104114532471\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from itertools import islice\n",
    "\n",
    "def mapper_tweet(tweet):\n",
    "    hashtags = re.findall(r'\\s#\\S+',tweet)\n",
    "    hashtags.extend(re.findall(r'^#\\S+', tweet))\n",
    "    for i in range(len(hashtags)):\n",
    "        hashtag = hashtags[i]\n",
    "        hashtag = re.sub(r'\\W+', '',hashtag)\n",
    "        hashtag = hashtag.lower()\n",
    "        hashtags[i] = hashtag\n",
    "    output = []\n",
    "    for i in range(len(hashtags)):\n",
    "        output.append((hashtags[i], 1))\n",
    "    return output\n",
    "\n",
    "def reducer_tweet(key, value):\n",
    "    return key, sum(value)\n",
    "\n",
    "def mapreduce_execute_tweet(tweets, mapper, reducer):\n",
    "    hashtags = map(mapper, tweets)\n",
    "    hashtags = list(hashtags)\n",
    "    the_hashtags = {}\n",
    "    for hashtag in hashtags:\n",
    "        for k, v in hashtag:\n",
    "            if k not in the_hashtags:\n",
    "                the_hashtags[k] = [v]\n",
    "            else:\n",
    "                the_hashtags[k].append(v)\n",
    "    output = [reducer(k, v) for k,v in the_hashtags.items()]\n",
    "    output.sort(key = lambda x: x[1])  \n",
    "    output = output[-10:]\n",
    "    output.reverse()\n",
    "    return output\n",
    "\n",
    "start_time = time.time()\n",
    "with open(\"test_set_tweets.txt\", encoding = \"utf8\") as file:\n",
    "    tweets = list(islice(file, 500000))\n",
    "print(mapreduce_execute_tweet(tweets, mapper_tweet, reducer_tweet))\n",
    "print(\"Time: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "head -500000 test_set_tweets.txt | sed -e 's/\\(.*\\)/\\L\\1/'| grep -o '^#\\S\\+\\|\\s#\\S\\+' | sed 's/\\W//g' | sort | uniq -c | sort | tail -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>449 followfriday</p>\n",
    "<p>451 musicmonday</p>\n",
    "<p>516 shoutout</p>\n",
    "<p>586 haiti</p>\n",
    "<p>601 random</p>\n",
    "<p>628 fail</p>\n",
    "<p>1017 mm</p>\n",
    "<p>1362 fb</p>\n",
    "<p>1799 nowplaying</p>\n",
    "<p>3522 ff</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "time head -500000 test_set_tweets.txt | sed -e 's/\\(.*\\)/\\L\\1/'| grep -o '^#\\S\\+|\\s#\\S\\+' | sed 's/\\W//g' | sort | uniq -c | sort | tail -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>real    0m11.963s</p>\n",
    "<p>user    0m11.700s</p>\n",
    "<p>sys     0m0.776s</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the time command on both, it looks like my shell script is slightly faster than my python. However, I was surprised that it was as close as it was since unix is usually a lot faster since it is low-level. I think it may be the piping that is causing the unix command to run a bit slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. a-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@RevRunWisdom:', 1229), ('@listensto', 939), ('@DonnieWahlberg', 523), ('@OGmuscles', 441), ('@addthis', 429), ('@breatheitin', 407), ('@justinbieber', 354), ('@MAV25', 347), ('@karlievoice', 304), ('@mtgcolorpie', 291)]\n",
      "Time: 11.382555723190308\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "def mapper_user(tweet):\n",
    "    users = re.findall(r'\\s@\\S+',tweet)\n",
    "    users.extend(re.findall(r'^@\\S+', tweet))\n",
    "    output = []\n",
    "    for i in range(len(users)):\n",
    "        output.append((users[i][1:], 1))\n",
    "    return output\n",
    "\n",
    "start_time = time.time()\n",
    "file = open(\"tweets.txt\", encoding=\"utf8\")\n",
    "tweets = file.readlines()\n",
    "print(mapreduce_execute_tweet(tweets, mapper_user, reducer_tweet))\n",
    "print(\"Time: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "cat tweets.txt | grep -o '\\s@\\S\\+\\|^@\\S+' | sed 's/^.//' | sort | uniq -c | sort | tail -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>291 @mtgcolorpie</p>\n",
    "<p>304 @karlievoice</p>\n",
    "<p>347 @MAV25</p>\n",
    "<p>354 @justinbieber</p>\n",
    "<p>407 @breatheitin</p>\n",
    "<p>429 @addthis</p>\n",
    "<p>441 @OGmuscles</p>\n",
    "<p>523 @DonnieWahlberg</p>\n",
    "<p>939 @listensto</p>\n",
    "<p>1229 @RevRunWisdom:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "time cat tweets.txt | grep -o '\\s@\\S\\+\\|^@\\S+' | sed 's/^.//' | sort | uniq -c | sort | tail -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>real    0m7.541s</p>\n",
    "<p>user    0m8.013s</p>\n",
    "<p>sys     0m0.743s</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the last question, the shell script takes a shorter time than the python function to run. However, this time the difference between unix and python was easy to see and the unix command ran significantly faster. This makes sense due to the low-level nature of unix which allows commands to run very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 a-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15004\n",
      "Time: 9.184471130371094\n"
     ]
    }
   ],
   "source": [
    "def mapper_two_hashtags(tweet):\n",
    "    hashtags = re.findall(r'\\s#\\S+',tweet)\n",
    "    hashtags.extend(re.findall(r'^#\\S+', tweet))\n",
    "    return (tweet, len(hashtags))\n",
    "\n",
    "def reducer_two_hashtags(tweet, length_hashtag):\n",
    "    return (tweet, length_hashtag >= 2)\n",
    "\n",
    "def mapreduce_execute_two_hashtags(tweets, mapper, reducer):\n",
    "    two_hashtags = map(mapper, tweets)\n",
    "    two_hashtags = list(two_hashtags)\n",
    "    result = 0\n",
    "    for i in range(len(two_hashtags)):\n",
    "        two_hashtags[i] = reducer_two_hashtags(two_hashtags[i][0], two_hashtags[i][1])\n",
    "        if two_hashtags[i][1]:\n",
    "            result += 1\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "file = open(\"tweets.txt\", encoding=\"utf8\")\n",
    "tweets = file.readlines()\n",
    "print(mapreduce_execute_two_hashtags(tweets, mapper_two_hashtags, reducer_two_hashtags))\n",
    "print(\"Time: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "cat tweets.txt | grep -o -n '^#\\S\\+\\|\\s#\\S\\+'| cut -d : -f1 | uniq -c | awk '$1 > 1 {count++} END {print count}' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "time cat tweets.txt | grep -o -n '^#\\S\\+\\|\\s#\\S\\+'| cut -d : -f1 | uniq -c | awk '$1 > 1 {count++} END {print count}' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>real    0m0.969s</p>\n",
    "<p>user    0m1.044s</p>\n",
    "<p>sys     0m0.168s</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to 1.2.1, the shell script is significantly faster than the python command. Again, this is probably due to unix being low level so scripts are able to run a lot faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Finding Reciprocal Followers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the files created in this question, I copied the contents of the file and pasted into markdown cells below the code that created it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "cat <(head -500000 test_set_tweets.txt) <(head -250000 training_set_tweets.txt) > tweets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the above unix command to create tweets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(135684, 135546), (40997, 41039), (40997, 62623), (40997, 40704), (40997, 201063), (70696, 70772), (70696, 60887), (15926, 15574), (20033, 19628), (93260, 93427), (93260, 65435), (41039, 40704), (33884, 34046), (33884, 34101), (3682, 5276), (31866, 32002), (78464, 78182), (89222, 89350), (19628, 19821), (122546, 102898), (22196, 76473), (32452, 32173), (62167, 33099), (80092, 80096), (100591, 100721), (134409, 134410), (63255, 65435), (63255, 13232), (18205, 13232), (192865, 192899), (201078, 201607), (65411, 65435), (58783, 58875), (41422, 23503)]\n",
      "Time: 17.772157669067383\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "start_time = time.time()\n",
    "myDF = pd.read_csv(\"edges.csv\", header = None, nrows=500000)\n",
    "true_vals = list(set(list(myDF[0])).intersection(set(list(myDF[1]))))\n",
    "miniDF = myDF[myDF[0].isin(true_vals)]\n",
    "miniDF = miniDF[miniDF[1].isin(true_vals)]\n",
    "\n",
    "def mapper_followers(first_id, second_id, df):\n",
    "    mutual = (((df[0] == first_id) & (df[1] == second_id)).any() & ((df[1] == first_id) & (df[0] == second_id)).any())\n",
    "    return first_id, second_id, mutual\n",
    "\n",
    "def reducer_followers(first_id, second_id, mutual):\n",
    "    if mutual:\n",
    "        return first_id, second_id\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def mapreduce_execute_followers(mapper_followers, reducer_followers, df, vals):\n",
    "    results = []\n",
    "    for i in range(len(vals)):\n",
    "        for j in range(i, len(vals)):\n",
    "            var = mapper_followers(vals[i], vals[j], df)\n",
    "            if var[2]:\n",
    "                results.append(reducer_followers(vals[i], vals[j], var[2]))\n",
    "    return results\n",
    "                \n",
    "results = mapreduce_execute_followers(mapper_followers, reducer_followers, miniDF, true_vals)\n",
    "print(results)\n",
    "print(\"Time: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Edges on original edges.csv: 500000\n",
      "Number of Nodes on original edges.csv: 249402\n",
      "Number of Edges on subset of edges.csv: 68\n",
      "Number of Nodes on subset of edges.csv: 55\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "for i in range(len(true_vals)):\n",
    "        for j in range(len(true_vals)):\n",
    "            var = mapper_followers(true_vals[i], true_vals[j], miniDF)\n",
    "            if var[2]:\n",
    "                vals.append(reducer_followers(true_vals[i], true_vals[j], var[2]))\n",
    "\n",
    "smaller_DF = pd.DataFrame(results, columns = [0, 1])\n",
    "\n",
    "writer = open(\"Q2_mutual_followers_python.txt\", \"w\")\n",
    "\n",
    "for i in range(len(vals)):\n",
    "    writer.write(str(vals[i][0]) + \", \" + str(vals[i][1]) + \"\\n\")\n",
    "writer.close()\n",
    "\n",
    "total_edges = len(myDF)\n",
    "total_nodes = len(set(myDF[0]).union(set(myDF[1])))\n",
    "\n",
    "\n",
    "subset_nodes = len(set(smaller_DF[0]).union(set(smaller_DF[1])))\n",
    "subset_edges = len(vals)\n",
    "\n",
    "print(\"Number of Edges on original edges.csv: \" + str(total_edges))\n",
    "print(\"Number of Nodes on original edges.csv: \" + str(total_nodes))\n",
    "print(\"Number of Edges on subset of edges.csv: \" + str(subset_edges))\n",
    "print(\"Number of Nodes on subset of edges.csv: \" + str(subset_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following is the contents of the file I created in 2c\n",
    "\n",
    "135684, 135546<br />\n",
    "40997, 41039<br />\n",
    "40997, 62623<br />\n",
    "40997, 40704<br />\n",
    "40997, 201063<br />\n",
    "70696, 70772<br />\n",
    "70696, 60887<br />\n",
    "15926, 15574<br />\n",
    "20033, 19628<br />\n",
    "93260, 93427<br />\n",
    "93260, 65435<br />\n",
    "41039, 40997<br />\n",
    "41039, 40704<br />\n",
    "33884, 34046<br />\n",
    "33884, 34101<br />\n",
    "3682, 5276<br />\n",
    "70772, 70696<br />\n",
    "31866, 32002<br />\n",
    "78464, 78182<br />\n",
    "89222, 89350<br />\n",
    "5276, 3682<br />\n",
    "62623, 40997<br />\n",
    "19628, 20033<br />\n",
    "19628, 19821<br />\n",
    "122546, 102898<br />\n",
    "22196, 76473<br />\n",
    "76473, 22196<br />\n",
    "32452, 32173<br />\n",
    "15574, 15926<br />\n",
    "62167, 33099<br />\n",
    "80092, 80096<br />\n",
    "80096, 80092<br />\n",
    "100591, 100721<br />\n",
    "93427, 93260<br />\n",
    "34046, 33884<br />\n",
    "32002, 31866<br />\n",
    "40704, 40997<br />\n",
    "40704, 41039<br />\n",
    "89350, 89222<br />\n",
    "134409, 134410<br />\n",
    "134410, 134409<br />\n",
    "63255, 65435<br />\n",
    "63255, 13232<br />\n",
    "18205, 13232<br />\n",
    "34101, 33884<br />\n",
    "33099, 62167<br />\n",
    "192865, 192899<br />\n",
    "78182, 78464<br />\n",
    "201063, 40997<br />\n",
    "19821, 19628<br />\n",
    "100721, 100591<br />\n",
    "201078, 201607<br />\n",
    "135546, 135684<br />\n",
    "192899, 192865<br />\n",
    "65411, 65435<br />\n",
    "201607, 201078<br />\n",
    "65435, 93260<br />\n",
    "65435, 63255<br />\n",
    "65435, 65411<br />\n",
    "58783, 58875<br />\n",
    "32173, 32452<br />\n",
    "13232, 63255<br />\n",
    "13232, 18205<br />\n",
    "41422, 23503<br />\n",
    "23503, 41422<br />\n",
    "60887, 70696<br />\n",
    "102898, 122546<br />\n",
    "58875, 58783<br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "head edges.csv -n 500000 | awk -F, '{if ($1 > $2){var = $1; $1 = $2; $2 = var;} print $0}' | sed 's/\\W/,/g' | sort | uniq -d | awk -F, '{print $1\",\"$2\"\\n\"$2\",\"$1}' > Q2_friends_unix.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the file created look something like the following..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100591,100721<br />\n",
    "100721,100591<br />\n",
    "102898,122546<br />\n",
    "122546,102898<br />\n",
    "13232,18205<br />\n",
    "18205,13232<br />\n",
    "13232,63255<br />\n",
    "63255,13232<br />\n",
    "134409,134410<br />\n",
    "134410,134409<br />\n",
    "135546,135684<br />\n",
    "135684,135546<br />\n",
    "15574,15926<br />\n",
    "15926,15574<br />\n",
    "192865,192899<br />\n",
    "192899,192865<br />\n",
    "19628,19821<br />\n",
    "19821,19628<br />\n",
    "19628,20033<br />\n",
    "20033,19628<br />\n",
    "201078,201607<br />\n",
    "201607,201078<br />\n",
    "22196,76473<br />\n",
    "76473,22196<br />\n",
    "23503,41422<br />\n",
    "41422,23503<br />\n",
    "31866,32002<br />\n",
    "32002,31866<br />\n",
    "32173,32452<br />\n",
    "32452,32173<br />\n",
    "33099,62167<br />\n",
    "62167,33099<br />\n",
    "33884,34046<br />\n",
    "34046,33884<br />\n",
    "33884,34101<br />\n",
    "34101,33884<br />\n",
    "3682,5276<br />\n",
    "5276,3682<br />\n",
    "40704,40997<br />\n",
    "40997,40704<br />\n",
    "40704,41039<br />\n",
    "41039,40704<br />\n",
    "40997,201063<br />\n",
    "201063,40997<br />\n",
    "40997,41039<br />\n",
    "41039,40997<br />\n",
    "40997,62623<br />\n",
    "62623,40997<br />\n",
    "58783,58875<br />\n",
    "58875,58783<br />\n",
    "60887,70696<br />\n",
    "70696,60887<br />\n",
    "63255,65435<br />\n",
    "65435,63255<br />\n",
    "65411,65435<br />\n",
    "65435,65411<br />\n",
    "65435,93260<br />\n",
    "93260,65435<br />\n",
    "70696,70772<br />\n",
    "70772,70696<br />\n",
    "78182,78464<br />\n",
    "78464,78182<br />\n",
    "80092,80096<br />\n",
    "80096,80092<br />\n",
    "89222,89350<br />\n",
    "89350,89222<br />\n",
    "93260,93427<br />\n",
    "93427,93260<br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "time head edges.csv -n 500000 | awk -F, '{if ($1 > $2){var = $1; $1 = $2; $2 = var;} print $0}' | sed 's/\\W/,/g' | sort | uniq -d | awk -F, '{print $1\",\"$2\"\\n\"$2\",\"$1}' > Q2_friends_unix.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>real    0m4.768s</p>\n",
    "<p>user    0m5.716s</p>\n",
    "<p>sys     0m0.261s</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Unix is faster than Python. This makes sense as my python mapreduce() function uses two for loops to parse all the data which was inefficient, making my python function significantly slower than my shell script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Finding Friend of Friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(135684, 135546), (40997, 41039), (40997, 62623), (40997, 40704), (40997, 201063), (70696, 70772), (70696, 60887), (15926, 15574), (20033, 19628), (93260, 93427), (93260, 65435), (41039, 40997), (41039, 40704), (33884, 34046), (33884, 34101), (3682, 5276), (70772, 70696), (31866, 32002), (78464, 78182), (89222, 89350), (5276, 3682), (62623, 40997), (19628, 20033), (19628, 19821), (122546, 102898), (22196, 76473), (76473, 22196), (32452, 32173), (15574, 15926), (62167, 33099), (80092, 80096), (80096, 80092), (100591, 100721), (93427, 93260), (34046, 33884), (32002, 31866), (40704, 40997), (40704, 41039), (89350, 89222), (134409, 134410), (134410, 134409), (63255, 65435), (63255, 13232), (18205, 13232), (34101, 33884), (33099, 62167), (192865, 192899), (78182, 78464), (201063, 40997), (19821, 19628), (100721, 100591), (201078, 201607), (135546, 135684), (192899, 192865), (65411, 65435), (201607, 201078), (65435, 93260), (65435, 63255), (65435, 65411), (58783, 58875), (32173, 32452), (13232, 63255), (13232, 18205), (41422, 23503), (23503, 41422), (60887, 70696), (102898, 122546), (58875, 58783)]\n"
     ]
    }
   ],
   "source": [
    "def mapper_friends(first_friend, second_friend, df):\n",
    "    cond1 = df[0].isin([first_friend,second_friend])\n",
    "    cond2 = df[1].isin([first_friend,second_friend])\n",
    "    mutual_friends = df[cond1 | cond2]\n",
    "    mutual_friends = list(set(list(mutual_friends[0])).intersection(set(list(mutual_friends[1]))))\n",
    "    actual_friends = []\n",
    "    for i in range(len(mutual_friends)):\n",
    "        if mutual_friends[i] != first_friend and mutual_friends[i] != second_friend:\n",
    "            if mapper_followers(mutual_friends[i], first_friend, df)[2] and mapper_followers(mutual_friends[i], second_friend, df)[2]:\n",
    "                actual_friends.append(mutual_friends[i])\n",
    "    return first_friend, second_friend, actual_friends\n",
    "\n",
    "def reducer_friends(first_friend, second_friend, actual_friends):\n",
    "    return first_friend, second_friend, len(actual_friends)\n",
    "\n",
    "def mapreduce_execute_friends(mapper, reducer, values, df):\n",
    "    mutual_friends = []\n",
    "    for i in range(len(values)):\n",
    "        var = mapper_friends(values[i][0], values[i][1], df)\n",
    "        mutual_friends.append(reducer_friends(var[0], var[1], var[2]))\n",
    "    return mutual_friends\n",
    "\n",
    "filer = open(\"Q2_mutual_followers_python.txt\", \"r\")\n",
    "my_values = []\n",
    "for line in filer.readlines():\n",
    "    ind = line.index(\",\")\n",
    "    my_values.append((int(line[0:ind]), int(line[ind + 1:].strip(\"\\n\"))))\n",
    "print(my_values)\n",
    "\n",
    "mutual_friends = mapreduce_execute_friends(mapper_friends, reducer_friends, my_values, miniDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friend #1: 40997, Friend #2: 41039, # of Mutual Friends: 1\n",
      "Friend #1: 40997, Friend #2: 40704, # of Mutual Friends: 1\n",
      "Friend #1: 41039, Friend #2: 40997, # of Mutual Friends: 1\n",
      "Friend #1: 41039, Friend #2: 40704, # of Mutual Friends: 1\n",
      "Friend #1: 40704, Friend #2: 40997, # of Mutual Friends: 1\n",
      "Friend #1: 40704, Friend #2: 41039, # of Mutual Friends: 1\n",
      "Friend #1: 135684, Friend #2: 135546, # of Mutual Friends: 0\n",
      "Friend #1: 40997, Friend #2: 62623, # of Mutual Friends: 0\n",
      "Friend #1: 40997, Friend #2: 201063, # of Mutual Friends: 0\n",
      "Friend #1: 70696, Friend #2: 70772, # of Mutual Friends: 0\n"
     ]
    }
   ],
   "source": [
    "mutual_friends.sort(key = lambda x: x[2], reverse=True)\n",
    "mutual_friends = mutual_friends[:10]\n",
    "for i in range(len(mutual_friends)):\n",
    "    print(\"Friend #1: \" + str(mutual_friends[i][0]) + \", Friend #2: \" + str(mutual_friends[i][1]) + \", # of Mutual Friends: \" + str(mutual_friends[i][2]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
